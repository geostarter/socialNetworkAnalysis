{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eritrea Twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name: Coleman Shepard <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Authentication Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your consumer key and secret inside the quotes below\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "\n",
    "# Insert your access key and secret inside the quotes below\n",
    "access_token_key = \"\"\n",
    "access_token_secret = \"\"\n",
    "\n",
    "print(\"Consumer and access keys and secrets have been successfully added\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Search for and print tweets using the 'search/tweets' endpoint \n",
    "\n",
    "# This line allows us to access the TwitterAPI library\n",
    "from TwitterAPI import TwitterAPI\n",
    "import pprint\n",
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect and Create a Cursor for a Postgres Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of writing the data collected from Twitter to a csv file, I chose to write the streamed data to a postgres database using the psycopg2 module in Python. This way I do not have to worry about any cocurrency issues when I query data from the database if data is still being writing to it. This also allows multiple users/scripts to write to the database which could be useful with multiple people working on the same project. The database is locally hosted (At the moment), so passwords and other information are close to default. If the database was hosted somewhere, I would explore the security measures that need to be in place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a connection to a database in Postgres (Local)\n",
    "twitter_connection = psycopg2.connect(user = \"tweet\",\n",
    "                                  password = \"ggez\",\n",
    "                                  host = \"127.0.0.1\",\n",
    "                                  port = \"5433\",\n",
    "                                  database = \"twitter\")\n",
    "\n",
    "# Needed for connection\n",
    "cursor = twitter_connection.cursor()\n",
    "\n",
    "# Print PostgreSQL Connection properties\n",
    "print (twitter_connection.get_dsn_parameters(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a table in the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A database called twitter was created through PgAdmin, but I wanted to practice creating tables with desired schemas in Python. At this point, I just assigned a Primary Key which will correspond to a counter variable running the stream for tweets. Right now, I'm not sure if this is the best way to go about this, especially if I were to index it. A clustered index around hashtags may prove to be better for my goal. At the moment, I'm just worried about getting going with Postgres & Python. I may make alterations down the line to optimize the retrieval of information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for Postgres Table Information Collection\n",
    "Table = \"\"\"CREATE TABLE twitter_t\n",
    "                (ID INT PRIMARY KEY NOT NULL,\n",
    "                TIME REAL,\n",
    "                NAME TEXT[],\n",
    "                FULL_TEXT TEXT[],\n",
    "                HASHTAG TEXT[],\n",
    "                COORDINATE TEXT,\n",
    "                GEO TEXT,\n",
    "                PLACE TEXT,\n",
    "                FAV_COUNT INT,\n",
    "                QUOTE_COUNT INT,\n",
    "                REPLY_COUNT INT,\n",
    "                RETWEET_COUNT INT,\n",
    "                STATUS_COUNT INT,\n",
    "                SCREEN_NAME TEXT,\n",
    "                FRIENDS_COUNT INT);\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Table Command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute CREATE TABLE command\n",
    "cursor.execute(Table)\n",
    "\n",
    "# Commit the action to the database\n",
    "twitter_connection.commit()\n",
    "\n",
    "# Close the cursor\n",
    "twitter_connection.close()\n",
    "print(\"Table created successfully in PostgreSQL \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the script I use to gather Twitter data and write it out to a record in my database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creates a connection to a database in Postgres (Local)\n",
    "twitter_connection = psycopg2.connect(user = \"tweet\",\n",
    "                                  password = \"ggez\",\n",
    "                                  host = \"127.0.0.1\",\n",
    "                                  port = \"5433\",\n",
    "                                  database = \"twitter\")\n",
    "# Needed for connection\n",
    "cursor = twitter_connection.cursor()\n",
    "\n",
    "\n",
    "print(\"Starting TwitterAPI\")\n",
    "api = TwitterAPI(consumer_key, consumer_secret, access_token_key, access_token_secret,)\n",
    "\n",
    "# Look for keywords in tweets\n",
    "keywords = \"eritrea\",\"TPLF\", \"AbiyAhmed\", \"IsaiasAfewerki\", \"PFDJ\",\"EPRDF\",\"FreeEritrea\", \"IStandWithEritrea\",\"#IStandWithEritrea\",\"#Eritrea\",\"HandsOffEritrea\", \"#HandsOffEritrea\",\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        print(\"Setting up filter request\")\n",
    "        # Notice we can add keyword filters (called 'track' term in Twitter)\n",
    "        r = api.request('statuses/filter', {'track': keywords})\n",
    "\n",
    "        # Count for database entry (Mistake)\n",
    "        count = 4666\n",
    "\n",
    "\n",
    "        print(\"Begin capturing tweets\")\n",
    "        for tweet in r:\n",
    "\n",
    "            hashtags = [i['text'] + \" \"  for i in tweet['entities']['hashtags']]\n",
    "\n",
    "            coords = tweet['coordinates']\n",
    "        #     print(hashtags)\n",
    "        #     print(\"ID\",tweet['id'])\n",
    "        #     print(\"TIME\", tweet['created_at'])\n",
    "        #     print(\"NAME\",tweet['user']['name'])\n",
    "        #     print(\"Full Text\",tweet['text'])\n",
    "        #     print(\"Hashtag\",tweet['entities']['hashtags'])\n",
    "            print(\"Coordinates\",tweet['coordinates'])\n",
    "            print(\"Geo\",tweet['geo'])\n",
    "            print(\"Place\",tweet['place'])\n",
    "        #     print(\"Fav_Count\",tweet['favorite_count'])\n",
    "        #     print(\"Quote_Count\",tweet['quote_count'])\n",
    "        #     print(\"Reply_Count\",tweet['reply_count'])\n",
    "        #     print(\"Retweet\", tweet['retweet_count'])\n",
    "        #     print(\"Statuses_Count\", tweet['user']['statuses_count'])\n",
    "            print(\"Screen_Name\", tweet['user']['screen_name'])\n",
    "            print(\"Friends_Count\", tweet['user']['friends_count'])\n",
    "\n",
    "            if tweet[\"retweeted\"] == True:\n",
    "                print(\"TRUE\")\n",
    "\n",
    "            if 'extended_tweet' in tweet:\n",
    "\n",
    "                text = tweet['extended_tweet']['full_text']\n",
    "            else:\n",
    "                text = tweet['text']\n",
    "\n",
    "            if 'coordinates' in tweet and tweet['coordinates'] != None:\n",
    "                coords = str((tweet['coordinates'][\"coordinates\"][0],tweet['coordinates'][\"coordinates\"][1])) # Add the tweet coordinates to the list\n",
    "                print(tweet['coordinates'])\n",
    "            else:\n",
    "                coords = tweet['coordinates']# If the tweet does not have coordinates then skip it\n",
    "\n",
    "\n",
    "            if tweet['place'] != None:\n",
    "                place = str(tweet['place'][\"full_name\"]) # Add the tweet coordinates to the list\n",
    "\n",
    "            else:\n",
    "                place = tweet['place'] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cursor.execute(\"\"\" INSERT INTO twitter_t (ID, TIME, NAME, FULL_TEXT, HASHTAG,COORDINATE,GEO,PLACE,\n",
    "                                                             FAV_COUNT,QUOTE_COUNT,REPLY_COUNT,RETWEET_COUNT,STATUS_COUNT,\n",
    "                                                             SCREEN_NAME,FRIENDS_COUNT) VALUES (%s, %s, %s, %s, %s,\n",
    "                                                             %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\" , (count, time.time(), [tweet['user']['name']],[text],\n",
    "                                                                                                           hashtags, coords, tweet['geo'], place, \n",
    "                                                                                                           tweet['favorite_count'],tweet['quote_count'], tweet['reply_count'],\n",
    "                                                                                                           tweet['retweet_count'],tweet['user']['statuses_count'], \n",
    "                                                                                                           [tweet['user']['screen_name']],tweet['user']['friends_count']))\n",
    "            twitter_connection.commit()\n",
    "\n",
    "            # Add 1 to count and if count is over 10 then stop capturing tweets\n",
    "            count = count + 1\n",
    "            print(count)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    time.sleep(15)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
